{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching URLs for query: ML is easy.\n",
      "Fetched URLs:\n",
      "https://www.reddit.com/r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/\n",
      "https://machine-learning-made-simple.medium.com/why-you-will-struggle-with-machine-learning-677403d04c7c\n",
      "https://www.quora.com/Which-one-is-easy-to-learn-among-machine-learning-and-artificial-intelligence-Can-I-learn-ML-before-AI\n",
      "\n",
      "Scraping https://www.reddit.com/r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/...\n",
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Reddit and its partners use cookies and similar technologies to provide you with a better experience.\n",
      "\n",
      "By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising.\n",
      "\n",
      "By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of our platform.\n",
      "\n",
      "For more information, please see our Cookie \n",
      "\n",
      "Scraping https://machine-learning-made-simple.medium.com/why-you-will-struggle-with-machine-learning-677403d04c7c...\n",
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Why you will struggle with Machine Learning\n",
      "\n",
      "A Prominent Math YouTuber inspired this article Devansh ¬∑ Follow 6 min read ¬∑ Jan 27, 2022 -- Listen Share\n",
      "\n",
      "To help me understand you fill out this survey (anonymous)\n",
      "\n",
      "In my free time, I watch a lot of Math/AI videos. Not only do these videos introduce me to new concepts/implementations, but they also help me learn how to communicate my ideas and knowledge better. A large portion of my ability to explain complex definitions and research comes from wat\n",
      "\n",
      "Scraping https://www.quora.com/Which-one-is-easy-to-learn-among-machine-learning-and-artificial-intelligence-Can-I-learn-ML-before-AI...\n",
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Something went wrong. Wait a moment and try again.\n",
      "\n",
      "Try again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Dive into anything',\n",
       "  'content': 'Reddit and its partners use cookies and similar technologies to provide you with a better experience.\\n\\nBy accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising.\\n\\nBy rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of our platform.\\n\\nFor more information, please see our Cookie Notice and our Privacy Policy.',\n",
       "  'url': 'https://www.reddit.com/r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/',\n",
       "  'publisher': 'Reddit'},\n",
       " {'title': 'Why you will struggle with Machine Learning',\n",
       "  'content': 'Why you will struggle with Machine Learning\\n\\nA Prominent Math YouTuber inspired this article Devansh ¬∑ Follow 6 min read ¬∑ Jan 27, 2022 -- Listen Share\\n\\nTo help me understand you fill out this survey (anonymous)\\n\\nIn my free time, I watch a lot of Math/AI videos. Not only do these videos introduce me to new concepts/implementations, but they also help me learn how to communicate my ideas and knowledge better. A large portion of my ability to explain complex definitions and research comes from watching other fantastic teachers teach these ideas. If you follow my content, you know how much I recommend watching YouTubers/content creators to keep up with the industry and to constantly stay on the cutting edge.\\n\\nMany people including myself found this video very valuable. Make sure you give ritvikmath some love\\n\\nA very interesting video I saw recently was, ‚ÄúSo ‚Ä¶ What Actually is a Matrix ? : Data Science Basics‚Äù by ritvikmath. In that video, he introduces the idea of a matrix from both computer science (coding) and mathematical perspectives. He goes on to show where each of these perspectives is useful to frame and tackle problems. Even if you‚Äôre familiar with the topics, I would suggest watching the video. Going over the basics can occasionally lead to ‚Äúaha‚Äù moments, as it did for me. I gained insight into why so many people struggle with learning Machine Learning. In this article, I will share why you will struggle as you learn ML. Then we‚Äôll talk about how you can overcome this. Because, even though ML is hard, you can excel at it.\\n\\nWhy people struggle with Machine Learning.\\n\\nAs I was scrolling through social media, looking for interesting ideas/discussions, I came across this. It was a message posted on Twitter by someone that was frustrating while trying to learn Machine Learning. We‚Äôll call the sender Steven.\\n\\nGo online and you will see this sentiment very often.\\n\\nWhat stands out to me here is the final part of the message. Steven is struggling and is consistently Googling things. Googling for Machine Learning can be particularly vicious. This is because depending on the context, your application of a concept changes. Take Steve‚Äôs example of calculus. In most of my day-to-day life, I don‚Äôt really use it for my ML functions. Keras and Tensorflow handle the backend of error propagation and error calculation for me. So my knowledge of calculus is more helpful in helping me understand papers and optimizations and not as much in most implementations.\\n\\nHowever, occasionally I have to model situations and variable distributions as functions. Being able to check if the functions are smooth and differentiable is a useful skill. Both these skills require me to be proficient at different aspects of calculus. They require viewing the concepts/literature through different lenses.\\n\\nThink back to Ritvik‚Äôs video. He talks of Matrices through the eyes of both a Computer Science student and a Math student. However, in Machine Learning, you will use them in both ways. Your models will use matrices to compute the results going b/w layers etc. These operations are the more mathematical side of matrices. However, that‚Äôs not all. Good use of matrices comes when dealing with relational databases. Remember, most dataframes are loaded as matrices. When operating on these, there are tons of little optimizations you can make to reduce the costs of loading the data onto your system. This requires an understanding of matrices from a Computer Science/Hardware perspective. And it is as much a part of ML as the other bit.\\n\\nMatrices are both used to store data (sets of vectors) and in the computations (multiplication with weights)\\n\\nMachine Learning is hard because it requires you to be able to think from different perspectives. You have to be willing to switch from a Math/theoretical perspective to more computer-oriented thinking while approaching the same problem. Add to this the complexities of most modern domains, and you can see why it is a struggle to get into. For a rather extreme example of this, check out, Paper shows why you will struggle at Machine Learning. In that article, I break down the most complicated paper I‚Äôve read till date. I spent a solid month on that paper, trying to understand the details. The reason I found this paper so challenging was because of how many domains/ideas it covered. It was quite impressive\\n\\nHow can you learn ML\\n\\nThis is bound to be on your mind right now. It‚Äôs not easy to excel in both Math and CS. But fear not, I got you.\\n\\nThere is one thing that will help you do well in Machine Learning: doing bad machine learning. You might be confused by this. However, this is really all there is to it.\\n\\nPhoto by Brett Jordan on Unsplash\\n\\nYou will have to start small and keep at learning. First, you‚Äôll set up your environment and copy a project from MachineLearningMastery. Then you‚Äôll tweak a few hyperparameters. Eventually, you‚Äôll experiment with a few other models/metrics. Now you‚Äôll work on a completely new dataset. You‚Äôll come across weird learning curves/errors which will make you test other kinds of preprocessing. And finally, you‚Äôll end up conceptualizing and creating your own project, from data collection to model deployment.\\n\\nIn the beginning, you will struggle and connecting all these ideas will seem like magic. This won‚Äôt last.\\n\\nAny course/expert that claims that they can make you a Machine Learning an expert in 3 months/1 year is a scam. Learning ML is a lifelong commitment. People will push the normal every year, and if you don‚Äôt keep up, you will fall behind. The results are exponential though. Within a year of reading your first paper, you will notice how much easier it is for you to go through literature and make connections between different ideas.\\n\\nI started my Machine Learning journey almost 6 years ago. If you read that article, you‚Äôll know that my exposure to AI was gradual. I experimented and failed. I did lots of things. It was only from Jun 2020 that I really did Hardcore ML on my own. It took me 4 years to really start making deep, meaningful contributions in the field on my own.\\n\\nIf you want a full roadmap to learn Machine Learning/AI in 2022, check out, ‚ÄúHow to learn Machine Learning in 2022\". It provides a proven roadmap to get you proficient at ML. The article links to tons of free resources, so you will be able to learn free of cost. Just remember, Rome wasn‚Äôt built in a day. While you‚Äôre learning the basics and looking at all the complex developments, the goal will seem very far away.\\n\\nIf you liked this article, check out my other content. I post regularly on Medium, YouTube, Twitter, and Substack (all linked below). I focus on Artificial Intelligence, Machine Learning, Technology, and Software Development. If you‚Äôre preparing for coding interviews check out: Coding Interviews Made Simple, my weekly newsletter. You can get the premium version for less than 0.5 USD dollars/day. The premium version will unlock high-quality solutions to weekly coding problems, special discussion posts, and a great community. It has helped a ton of people in their preparations.\\n\\nFeel free to reach out if you have any interesting jobs/projects/ideas for me as well. Always happy to hear you out.\\n\\nFor monetary support of my work following are my Venmo and Paypal. Any amount is appreciated and helps a lot. Donations unlock exclusive content such as paper analysis, special code, consultations, and specific coaching:\\n\\nVenmo: https://account.venmo.com/u/FNU-Devansh\\n\\nPaypal: paypal.me/ISeeThings\\n\\nReach out to me\\n\\nIf you‚Äôd like to discuss tutoring, text me on LinkedIn, IG, or Twitter. Check out the free Robinhood referral link. We both get a free stock (you don‚Äôt have to put any money), and there is no risk to you. Not using it is just losing free money.\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let‚Äôs connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819\\n\\nIf you‚Äôre preparing for coding/technical interviews: https://codinginterviewsmadesimple.substack.com/\\n\\nGet a free stock on Robinhood: https://join.robinhood.com/fnud75',\n",
       "  'url': 'https://machine-learning-made-simple.medium.com/why-you-will-struggle-with-machine-learning-677403d04c7c',\n",
       "  'publisher': 'Medium'},\n",
       " {'title': 'Which one is easy to learn among machine learning and artificial intelligence? Can I learn ML before AI?',\n",
       "  'content': 'Something went wrong. Wait a moment and try again.\\n\\nTry again',\n",
       "  'url': 'https://www.quora.com/Which-one-is-easy-to-learn-among-machine-learning-and-artificial-intelligence-Can-I-learn-ML-before-AI',\n",
       "  'publisher': 'Quora'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import query_articles\n",
    "importlib.reload(query_articles)\n",
    "import query_articles\n",
    "\n",
    "CLAIM = \"ML is easy.\"\n",
    "ARTICLES = query_articles.query_articles(CLAIM)\n",
    "if len(ARTICLES) == 0:\n",
    "    raise ValueError(\"No articles retrieved.\")\n",
    "ARTICLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stance Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mazerti/.anaconda/envs/tuesday-rush/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading model ...\n",
      "==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060 Laptop GPU. Max memory: 5.698 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.4 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded in 8.05535364151001 s\n",
      "Analyzing article Dive into anything from Reddit...\n",
      "Done in 4.0869224071502686.\n",
      "Analyzing article Why you will struggle with Machine Learning from Medium...\n",
      "Done in 4.615100383758545.\n",
      "Analyzing article Which one is easy to learn among machine learning and artificial intelligence? Can I learn ML before AI? from Quora...\n",
      "Done in 4.048301696777344.\n",
      "r more information, please see our Cookie Notice and our Privacy Policy.\n",
      "```assistant\n",
      "\n",
      "**Overall Comment:** The claim that \"ML is easy\" appears to be unrelated to the content discussed in the article, which revolves around discussing and explaining how cookies work and Reddit's privacy policy. The article discusses various aspects of cookies, including their usage and importance on the platform, but does not directly address the complexity or ease of machine learning algorithms.\n",
      "\n",
      "| Label              | Probability |\n",
      "|--------------------|-------------|\n",
      "| Agrees             | 0%         |\n",
      "| Disagrees          | 0%         |\n",
      "| Unrelated          | 99.9%      |\n",
      "| An error occurred  | 0%         |\n",
      "-----------------------------------------------\n",
      ".com/\n",
      "\n",
      "Get a free stock on Robinhood: https://join.robinhood.com/fnud75\n",
      "```assistant\n",
      "\n",
      "**Overall Comment:** \n",
      "The article discusses why individuals may struggle with learning Machine Learning. According to the author, a key aspect of struggling with ML is the requirement to think from multiple perspectives. This involves switching between theoretical math and computer science approaches to tackling problems. Additionally, the author suggests that overcoming difficulties with ML takes practice and persistence, highlighting that doing bad machine learning can eventually become good machine learning.\n",
      "\n",
      "| Label              | Probability |\n",
      "|--------------------|-------------|\n",
      "| Agrees             | 30%       |\n",
      "| Disagrees          | 50%        |\n",
      "| Unrelated          | 20%         |\n",
      "| An error occurred  | 0%         |\n",
      "-----------------------------------------------\n",
      "**  \n",
      "```  \n",
      "Something went wrong. Wait a moment and try again.\n",
      "\n",
      "Try again\n",
      "```assistant\n",
      "\n",
      "**Overall Comment:** The task was to evaluate the relationship between a given claim (\"ML is easy\") and an article's content. Upon analysis, I found that the article appears to be missing information due to the error message \"Something went wrong. Wait a moment and try again.\" The claim of ML being easy cannot be supported or refuted since no relevant content exists in the provided article. Hence, the probabilities for all labels were set to 0%.\n",
      "\n",
      "| Label              | Probability |\n",
      "|--------------------|-------------|\n",
      "| Agrees             | 0           |\n",
      "| Disagrees          | 0           |\n",
      "| Unrelated          | 0           |\n",
      "| An error occurred  | 20.0        |\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "LOCAL = True\n",
    "if LOCAL:\n",
    "    import inference_local\n",
    "    importlib.reload(inference_local)\n",
    "    import inference_local\n",
    "else:\n",
    "    import modal\n",
    "\n",
    "\n",
    "if LOCAL:\n",
    "    RESPONSES = inference_local.batch_infer_stances(CLAIM, ARTICLES)\n",
    "else:\n",
    "    batch_infer_stances = modal.Function.lookup(\"claim-checker\", \"batch_infer_stances\")\n",
    "    RESPONSES = batch_infer_stances.remote(CLAIM, ARTICLES)\n",
    "\n",
    "\n",
    "for RESPONSE in RESPONSES:\n",
    "    print(RESPONSE)\n",
    "    print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responses Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(89, 483), match='Overall Comment:** The claim that \"ML is easy\" ap>\n",
      "<re.Match object; span=(559, 594), match='| Agrees             | 0%         |'>\n",
      "<re.Match object; span=(595, 630), match='| Disagrees          | 0%         |'>\n",
      "<re.Match object; span=(631, 666), match='| Unrelated          | 99.9%      |'>\n",
      "<re.Match object; span=(667, 701), match='| An error occurred  | 0%         '>\n",
      "{'comment': 'The claim that \"ML is easy\" appears to be unrelated to the content discussed in the article, which revolves around discussing and explaining how cookies work and Reddit\\'s privacy policy. The article discusses various aspects of cookies, including their usage and importance on the platform, but does not directly address the complexity or ease of machine learning algorithms.', 'agrees': 0.0, 'disagrees': 0.0, 'unrelated': 99.9, 'error_flag': False}\n",
      "((0.0, 99.9), 'unrelated')\n",
      "-----------------------------------------------\n",
      "<re.Match object; span=(88, 602), match='Overall Comment:** \\nThe article discusses why in>\n",
      "<re.Match object; span=(678, 712), match='| Agrees             | 30%       |'>\n",
      "<re.Match object; span=(713, 748), match='| Disagrees          | 50%        |'>\n",
      "<re.Match object; span=(749, 785), match='| Unrelated          | 20%         |'>\n",
      "<re.Match object; span=(786, 820), match='| An error occurred  | 0%         '>\n",
      "{'comment': 'The article discusses why individuals may struggle with learning Machine Learning. According to the author, a key aspect of struggling with ML is the requirement to think from multiple perspectives. This involves switching between theoretical math and computer science approaches to tackling problems. Additionally, the author suggests that overcoming difficulties with ML takes practice and persistence, highlighting that doing bad machine learning can eventually become good machine learning.', 'agrees': 30.0, 'disagrees': 50.0, 'unrelated': 20.0, 'error_flag': False}\n",
      "((-20.0, 20.0), 'contradicts')\n",
      "-----------------------------------------------\n",
      "<re.Match object; span=(89, 536), match='Overall Comment:** The task was to evaluate the r>\n",
      "<re.Match object; span=(612, 648), match='| Agrees             | 0           |'>\n",
      "<re.Match object; span=(649, 685), match='| Disagrees          | 0           |'>\n",
      "<re.Match object; span=(686, 722), match='| Unrelated          | 0           |'>\n",
      "<re.Match object; span=(723, 758), match='| An error occurred  | 20.0        '>\n",
      "{'comment': 'The task was to evaluate the relationship between a given claim (\"ML is easy\") and an article\\'s content. Upon analysis, I found that the article appears to be missing information due to the error message \"Something went wrong. Wait a moment and try again.\" The claim of ML being easy cannot be supported or refuted since no relevant content exists in the provided article. Hence, the probabilities for all labels were set to 0%.', 'agrees': 0.0, 'disagrees': 0.0, 'unrelated': 0.0, 'error_flag': False}\n",
      "(None, 'error')\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import response_handler\n",
    "importlib.reload(response_handler)\n",
    "import response_handler\n",
    "\n",
    "for RESPONSE in RESPONSES:\n",
    "    RESULT_OBJECT = response_handler.parse_result(RESPONSE, error_threshold=20)\n",
    "    print(RESULT_OBJECT)\n",
    "    STANCE = response_handler.get_stance(RESULT_OBJECT)\n",
    "    print(STANCE)\n",
    "    print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mazerti/.anaconda/envs/tuesday-rush/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-02 18:02:44,197 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-01-02 18:02:44,219 - DEBUG - load_verify_locations cafile='/home/mazerti/.anaconda/envs/tuesday-rush/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2025-01-02 18:02:44,241 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-01-02 18:02:44,256 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2025-01-02 18:02:44,449 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6e7e8340>\n",
      "2025-01-02 18:02:44,450 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7c2f6f5169c0> server_hostname='api.gradio.app' timeout=3\n",
      "2025-01-02 18:02:44,457 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-01-02 18:02:44,458 - DEBUG - load_verify_locations cafile='/home/mazerti/.anaconda/envs/tuesday-rush/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2025-01-02 18:02:44,463 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=None socket_options=None\n",
      "2025-01-02 18:02:44,464 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6e330eb0>\n",
      "2025-01-02 18:02:44,465 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:44,465 - DEBUG - send_request_headers.complete\n",
      "2025-01-02 18:02:44,467 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:44,467 - DEBUG - send_request_body.complete\n",
      "2025-01-02 18:02:44,468 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:44,468 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Thu, 02 Jan 2025 17:02:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
      "2025-01-02 18:02:44,469 - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-01-02 18:02:44,469 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:44,469 - DEBUG - receive_response_body.complete\n",
      "2025-01-02 18:02:44,469 - DEBUG - response_closed.started\n",
      "2025-01-02 18:02:44,470 - DEBUG - response_closed.complete\n",
      "2025-01-02 18:02:44,470 - DEBUG - close.started\n",
      "2025-01-02 18:02:44,470 - DEBUG - close.complete\n",
      "2025-01-02 18:02:44,471 - DEBUG - load_ssl_context verify=False cert=None trust_env=True http2=False\n",
      "2025-01-02 18:02:44,472 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=3 socket_options=None\n",
      "2025-01-02 18:02:44,472 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6e331ea0>\n",
      "2025-01-02 18:02:44,473 - DEBUG - send_request_headers.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:44,473 - DEBUG - send_request_headers.complete\n",
      "2025-01-02 18:02:44,474 - DEBUG - send_request_body.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:44,474 - DEBUG - send_request_body.complete\n",
      "2025-01-02 18:02:44,475 - DEBUG - receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:44,483 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Thu, 02 Jan 2025 17:02:44 GMT'), (b'server', b'uvicorn'), (b'content-length', b'11732'), (b'content-type', b'text/html; charset=utf-8')])\n",
      "2025-01-02 18:02:44,483 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2025-01-02 18:02:44,484 - DEBUG - receive_response_body.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:44,484 - DEBUG - receive_response_body.complete\n",
      "2025-01-02 18:02:44,484 - DEBUG - response_closed.started\n",
      "2025-01-02 18:02:44,485 - DEBUG - response_closed.complete\n",
      "2025-01-02 18:02:44,485 - DEBUG - close.started\n",
      "2025-01-02 18:02:44,485 - DEBUG - close.complete\n",
      "2025-01-02 18:02:44,486 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-01-02 18:02:44,487 - DEBUG - load_verify_locations cafile='/home/mazerti/.anaconda/envs/tuesday-rush/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2025-01-02 18:02:44,493 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=30 socket_options=None\n",
      "2025-01-02 18:02:44,578 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/11\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:02:44,729 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6e7b85b0>\n",
      "2025-01-02 18:02:44,730 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7c2f6d3ce940> server_hostname='api.gradio.app' timeout=30\n",
      "2025-01-02 18:02:44,849 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6e7bbfd0>\n",
      "2025-01-02 18:02:44,849 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:44,850 - DEBUG - send_request_headers.complete\n",
      "2025-01-02 18:02:44,850 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:44,850 - DEBUG - send_request_body.complete\n",
      "2025-01-02 18:02:44,851 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:45,038 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 02 Jan 2025 17:02:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2025-01-02 18:02:45,039 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-01-02 18:02:45,039 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:45,039 - DEBUG - receive_response_body.complete\n",
      "2025-01-02 18:02:45,040 - DEBUG - response_closed.started\n",
      "2025-01-02 18:02:45,040 - DEBUG - response_closed.complete\n",
      "2025-01-02 18:02:45,040 - DEBUG - close.started\n",
      "2025-01-02 18:02:45,041 - DEBUG - close.complete\n",
      "2025-01-02 18:02:45,118 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6eb73460>\n",
      "2025-01-02 18:02:45,118 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:45,119 - DEBUG - send_request_headers.complete\n",
      "2025-01-02 18:02:45,119 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:45,120 - DEBUG - send_request_body.complete\n",
      "2025-01-02 18:02:45,120 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:45,314 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 02 Jan 2025 17:02:45 GMT'), (b'Content-Type', b'text/html; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'ContentType', b'application/json'), (b'Access-Control-Allow-Origin', b'*'), (b'Content-Encoding', b'gzip')])\n",
      "2025-01-02 18:02:45,315 - INFO - HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "2025-01-02 18:02:45,315 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-01-02 18:02:45,316 - DEBUG - receive_response_body.complete\n",
      "2025-01-02 18:02:45,316 - DEBUG - response_closed.started\n",
      "2025-01-02 18:02:45,316 - DEBUG - response_closed.complete\n",
      "2025-01-02 18:02:45,316 - DEBUG - close.started\n",
      "2025-01-02 18:02:45,317 - DEBUG - close.complete\n",
      "2025-01-02 18:02:46,164 - DEBUG - load_ssl_context verify=False cert=None trust_env=True http2=False\n",
      "2025-01-02 18:02:46,165 - DEBUG - connect_tcp.started host='8465bbdb4a0479bcac.gradio.live' port=443 local_address=None timeout=3 socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://8465bbdb4a0479bcac.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:02:46,438 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6eb724d0>\n",
      "2025-01-02 18:02:46,439 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7c2f6f5171c0> server_hostname='8465bbdb4a0479bcac.gradio.live' timeout=3\n",
      "2025-01-02 18:02:46,824 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7c2f6eb72920>\n",
      "2025-01-02 18:02:46,825 - DEBUG - send_request_headers.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:46,826 - DEBUG - send_request_headers.complete\n",
      "2025-01-02 18:02:46,827 - DEBUG - send_request_body.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:46,827 - DEBUG - send_request_body.complete\n",
      "2025-01-02 18:02:46,827 - DEBUG - receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:47,218 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 02 Jan 2025 17:02:47 GMT'), (b'Content-Type', b'text/html; charset=utf-8'), (b'Content-Length', b'11749'), (b'Connection', b'keep-alive'), (b'Server', b'uvicorn')])\n",
      "2025-01-02 18:02:47,219 - INFO - HTTP Request: HEAD https://8465bbdb4a0479bcac.gradio.live \"HTTP/1.1 200 OK\"\n",
      "2025-01-02 18:02:47,219 - DEBUG - receive_response_body.started request=<Request [b'HEAD']>\n",
      "2025-01-02 18:02:47,220 - DEBUG - receive_response_body.complete\n",
      "2025-01-02 18:02:47,220 - DEBUG - response_closed.started\n",
      "2025-01-02 18:02:47,220 - DEBUG - response_closed.complete\n",
      "2025-01-02 18:02:47,221 - DEBUG - close.started\n",
      "2025-01-02 18:02:47,221 - DEBUG - close.complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8465bbdb4a0479bcac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:02:47,225 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-01-02 18:02:47,495 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/launched HTTP/11\" 200 0\n",
      "2025-01-02 18:02:57,758 - DEBUG - Starting new HTTPS connection (1): www.google.com:443\n",
      "2025-01-02 18:02:57,956 - DEBUG - https://www.google.com:443 \"GET /search?q=ML+is+easy.&num=8&hl=en&start=0&safe=active HTTP/11\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching URLs for query: ML is easy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:02:59,399 - DEBUG - Starting new HTTPS connection (1): www.reddit.com:443\n",
      "2025-01-02 18:02:59,596 - DEBUG - https://www.reddit.com:443 \"GET /r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/ HTTP/11\" 302 412\n",
      "2025-01-02 18:02:59,598 - DEBUG - Resetting dropped connection: www.reddit.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched URLs:\n",
      "https://www.reddit.com/r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/\n",
      "https://machine-learning-made-simple.medium.com/why-you-will-struggle-with-machine-learning-677403d04c7c\n",
      "https://www.quora.com/Which-one-is-easy-to-learn-among-machine-learning-and-artificial-intelligence-Can-I-learn-ML-before-AI\n",
      "https://www.coursera.org/articles/is-machine-learning-hard\n",
      "https://www.nobledesktop.com/learn/machine-learning/how-difficult-is-it-to-learn-machine-learning\n",
      "https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471\n",
      "\n",
      "Scraping https://www.reddit.com/r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:02:59,853 - DEBUG - https://www.reddit.com:443 \"GET /r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/?rdt=63980 HTTP/11\" 200 None\n",
      "2025-01-02 18:03:00,362 - DEBUG - Starting new HTTPS connection (1): machine-learning-made-simple.medium.com:443\n",
      "2025-01-02 18:03:00,539 - DEBUG - https://machine-learning-made-simple.medium.com:443 \"GET /why-you-will-struggle-with-machine-learning-677403d04c7c HTTP/11\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Reddit and its partners use cookies and similar technologies to provide you with a better experience.\n",
      "\n",
      "By accepting all cookies, you agree to our use of cookies to deliver and maintain our services and site, improve the quality of Reddit, personalize Reddit content and advertising, and measure the effectiveness of advertising.\n",
      "\n",
      "By rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of our platform.\n",
      "\n",
      "For more information, please see our Cookie \n",
      "\n",
      "Scraping https://machine-learning-made-simple.medium.com/why-you-will-struggle-with-machine-learning-677403d04c7c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:03:00,668 - DEBUG - Starting new HTTPS connection (1): www.quora.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Why you will struggle with Machine Learning\n",
      "\n",
      "A Prominent Math YouTuber inspired this article Devansh ¬∑ Follow 6 min read ¬∑ Jan 27, 2022 -- Listen Share\n",
      "\n",
      "To help me understand you fill out this survey (anonymous)\n",
      "\n",
      "In my free time, I watch a lot of Math/AI videos. Not only do these videos introduce me to new concepts/implementations, but they also help me learn how to communicate my ideas and knowledge better. A large portion of my ability to explain complex definitions and research comes from wat\n",
      "\n",
      "Scraping https://www.quora.com/Which-one-is-easy-to-learn-among-machine-learning-and-artificial-intelligence-Can-I-learn-ML-before-AI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:03:01,006 - DEBUG - https://www.quora.com:443 \"GET /Which-one-is-easy-to-learn-among-machine-learning-and-artificial-intelligence-Can-I-learn-ML-before-AI HTTP/11\" 200 None\n",
      "2025-01-02 18:03:01,876 - DEBUG - Starting new HTTPS connection (1): www.coursera.org:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Something went wrong. Wait a moment and try again.\n",
      "\n",
      "Try again\n",
      "\n",
      "Scraping https://www.coursera.org/articles/is-machine-learning-hard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:03:02,600 - DEBUG - https://www.coursera.org:443 \"GET /articles/is-machine-learning-hard HTTP/11\" 200 None\n",
      "2025-01-02 18:03:03,125 - DEBUG - Starting new HTTPS connection (1): www.nobledesktop.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Content (First 500 characters):\n",
      "\n",
      "\n",
      "Scraping https://www.nobledesktop.com/learn/machine-learning/how-difficult-is-it-to-learn-machine-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:03:04,544 - DEBUG - https://www.nobledesktop.com:443 \"GET /learn/machine-learning/how-difficult-is-it-to-learn-machine-learning HTTP/11\" 200 None\n",
      "2025-01-02 18:03:04,684 - DEBUG - Starting new HTTPS connection (1): medium.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Content (First 500 characters):\n",
      "Discover the intriguing world of machine learning, its relationship with artificial intelligence, and its implications across various sectors. Dive into career paths such as Machine Learning Engineers, Data Scientists, and Business Intelligence Analysts, and learn the importance of mastering programming languages like Python or R and databases like MySQL to succeed in these roles. Key Insights Machine learning, a subcategory of artificial intelligence, requires proficiency in programming languag\n",
      "\n",
      "Scraping https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:03:05,225 - DEBUG - https://medium.com:443 \"GET /@ageitgey/machine-learning-is-fun-80ea3ec3c471 HTTP/11\" 200 None\n",
      "2025-01-02 18:03:05,423 - INFO - Scraped 6 articles.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraped Content (First 500 characters):\n",
      "What is machine learning?\n",
      "\n",
      "Machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem. Instead of writing code, you feed data to the generic algorithm and it builds its own logic based on the data.\n",
      "\n",
      "For example, one kind of algorithm is a classification algorithm. It can put data into different groups. The same classification algorithm used to recognize handwritten \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:03:05,734 - DEBUG - Adding (b':method', b'POST') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,734 - DEBUG - Encoding 3 with 7 bits\n",
      "2025-01-02 18:03:05,735 - DEBUG - Adding (b':scheme', b'https') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,735 - DEBUG - Encoding 7 with 7 bits\n",
      "2025-01-02 18:03:05,735 - DEBUG - Adding (b':path', b'/modal.client.ModalClient/FunctionGet') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,735 - DEBUG - Encoding 4 with 6 bits\n",
      "2025-01-02 18:03:05,736 - DEBUG - Encoding 27 with 7 bits\n",
      "2025-01-02 18:03:05,736 - DEBUG - Adding (b':authority', b'api.modal.com:443') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,736 - DEBUG - Encoding 1 with 6 bits\n",
      "2025-01-02 18:03:05,736 - DEBUG - Encoding 13 with 7 bits\n",
      "2025-01-02 18:03:05,737 - DEBUG - Adding (b'te', b'trailers') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,737 - DEBUG - Encoding 2 with 7 bits\n",
      "2025-01-02 18:03:05,737 - DEBUG - Encoding 6 with 7 bits\n",
      "2025-01-02 18:03:05,738 - DEBUG - Adding (b'content-type', b'application/grpc') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,738 - DEBUG - Encoding 31 with 6 bits\n",
      "2025-01-02 18:03:05,738 - DEBUG - Encoding 11 with 7 bits\n",
      "2025-01-02 18:03:05,738 - DEBUG - Adding (b'user-agent', b\"modal-client/0.70.1 (linux; cpython/3.10.15)'\") to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,738 - DEBUG - Encoding 58 with 6 bits\n",
      "2025-01-02 18:03:05,739 - DEBUG - Encoding 34 with 7 bits\n",
      "2025-01-02 18:03:05,739 - DEBUG - Adding (b'x-idempotency-key', b'85e4a94e-16a8-42f7-a2ca-9a6ed8296153') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,739 - DEBUG - Encoding 13 with 7 bits\n",
      "2025-01-02 18:03:05,739 - DEBUG - Encoding 26 with 7 bits\n",
      "2025-01-02 18:03:05,740 - DEBUG - Adding (b'x-retry-attempt', b'0') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,740 - DEBUG - Encoding 11 with 7 bits\n",
      "2025-01-02 18:03:05,740 - DEBUG - Encoding 1 with 7 bits\n",
      "2025-01-02 18:03:05,740 - DEBUG - Adding (b'x-modal-client-version', b'0.70.1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,740 - DEBUG - Encoding 16 with 7 bits\n",
      "2025-01-02 18:03:05,741 - DEBUG - Encoding 5 with 7 bits\n",
      "2025-01-02 18:03:05,741 - DEBUG - Adding (b'x-modal-client-type', b'1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,741 - DEBUG - Encoding 14 with 7 bits\n",
      "2025-01-02 18:03:05,741 - DEBUG - Encoding 1 with 7 bits\n",
      "2025-01-02 18:03:05,741 - DEBUG - Adding (b'x-modal-python-version', b'3.10.15') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,742 - DEBUG - Encoding 16 with 7 bits\n",
      "2025-01-02 18:03:05,742 - DEBUG - Encoding 5 with 7 bits\n",
      "2025-01-02 18:03:05,742 - DEBUG - Adding (b'x-modal-node', b'mazerti-ASUS-TUF-Gaming-F15-FX506HM-TUF566HM') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,742 - DEBUG - Encoding 9 with 7 bits\n",
      "2025-01-02 18:03:05,743 - DEBUG - Encoding 35 with 7 bits\n",
      "2025-01-02 18:03:05,743 - DEBUG - Adding (b'x-modal-platform', b'Linux-6.8.0_51_generic-x86_64') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,744 - DEBUG - Encoding 12 with 7 bits\n",
      "2025-01-02 18:03:05,744 - DEBUG - Encoding 22 with 7 bits\n",
      "2025-01-02 18:03:05,744 - DEBUG - Adding (b'x-modal-token-id', b'ak-HLgx4CHd5JiKIluu51ZSos') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,745 - DEBUG - Encoding 12 with 7 bits\n",
      "2025-01-02 18:03:05,745 - DEBUG - Encoding 20 with 7 bits\n",
      "2025-01-02 18:03:05,745 - DEBUG - Adding (b'x-modal-token-secret', b'as-lvSGANEGSqViUhZre9asLs') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,746 - DEBUG - Encoding 14 with 7 bits\n",
      "2025-01-02 18:03:05,746 - DEBUG - Encoding 20 with 7 bits\n",
      "2025-01-02 18:03:05,746 - DEBUG - Encoded header block to b'\\x83\\x87D\\x9bb\\x93\\xc8:\\x17%\\x06-I_A\\xe4\\x1d\\x17\\xa81jK\\x18m\\xa8\\x891\\xea\\xc4T\\xffA\\x8d\\x1df^\\x93\\xc8:\\x17!\\xe9\\xb8\\xd3L\\xff@\\x82I\\x7f\\x86M\\x835\\x05\\xb1\\x1f_\\x8b\\x1du\\xd0b\\r&=LMedz\\xa2\\xa4\\xf2\\x0e\\x85\\x89A\\x8bRX\\x02\\xee\\x81p\\xa9\\xfdPj\\xad\\xf3\\xf6\\xa1+\\xf4\\x99\\xcfS\\x0c\\xae\\x10.\\x16\\xff\\xbf\\xf5@\\x8d\\xf2\\xb1\\xa4-5\\x9d%\\xa8\\x9e\\x96\\xea__\\x9ay\\xb2\\xb47\\xda*\\xc1po,\\xd0\\xa5ua\\x88\\x83Y\\xf1\\xb8Y\\x1e\\x13\\xee\\x05\\xb6\\x7f@\\x8b\\xf2\\xb5\\x85M\\x9e\\x96\\x1aRZkO\\x81\\x07@\\x90\\xf2\\xb5\\'\\x90t,J\\x0cZ\\x92\\xb7r\\xd8\\x83\\x1e\\xaf\\x85\\x02\\xee\\x81p\\xff@\\x8e\\xf2\\xb5\\'\\x90t,J\\x0cZ\\x92\\xb2}V_\\x81\\x0f@\\x90\\xf2\\xb5\\'\\x90t-_\\xa4\\xcez\\x96\\xee[\\x10c\\xd5\\x85ep\\x81p\\xb7@\\x89\\xf2\\xb5\\'\\x90t-Q\\xe4/\\xa3\\xa4~\\xcbbL\\xb4;\\xb8n[\\x7f\\x0c+b\\x1d&\\xaae\\xb0\\x85\\xb5\\xb0\\xfe6\\x071\\xe8[\\x7f\\x0c-\\xb8\\xe6=\\x1f@\\x8c\\xf2\\xb5\\'\\x90t-]\\x03L\\xa7\\xb2\\x9f\\x96\\xcej\\xad\\xf2\\xb3\\x8b\\xbc\\xb8\"l1LZ\\x8ba\\x88\\xb7\\x97\\x9c\\x89\\xc6\\xbf@\\x8c\\xf2\\xb5\\'\\x90t,\\x93\\xf5-K\\x1aO\\x94\\x1fU\\xb1\\xe7\\x9b\\xcbW\\xb1\\xc8\\xdeSf\\xc9E\\xb6\\xb6\\x1f\\xdd\\xc7G@\\x8e\\xf2\\xb5\\'\\x90t,\\x93\\xf5-K \\xa4\\xb0\\xa9\\x94\\x1a\\x16\\xa3\\xbe\\xecP\\xe9\\xc1\\x8bwn&\\xe1?\\xed\\x85|h\\xce\\x8f'\n",
      "2025-01-02 18:03:05,881 - DEBUG - Decoding b' \\x88a\\x96\\xdf=\\xbfJ\\x00Je\\x1dJ\\x08\\x02m@\\xbbp\\x0c\\xdc\\x03jb\\xd1\\xbf_\\x8b\\x1du\\xd0b\\r&=LMed\\x00\\x8e\\x9a\\xca\\xc8\\xb0\\xc8B\\xd6\\x95\\x8bQ\\x0f!\\xaa\\x9b\\x914\\x85\\xa9&O\\xaf\\xa5$,\\xb4\\r%\\xfaRof\\xaf\\x00\\x91Bl1\\x12\\xb2l\\x1dH\\xac\\xf6%d\\x14\\x96\\xd8d\\xfa\\x9a\\xa4~V\\x1c\\xc5\\x81\\x90\\xb6\\xcb\\x80\\x00>\\xd45D\\xa2\\xd9\\x0b\\xba\\xd8\\xef\\x9e\\x91\\x9a\\xa4\\x7f'\n",
      "2025-01-02 18:03:05,882 - DEBUG - Decoded 0, consumed 1 bytes\n",
      "2025-01-02 18:03:05,882 - DEBUG - Resizing header table to 0 from 4096\n",
      "2025-01-02 18:03:05,883 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:03:05,883 - DEBUG - Decoded (b':status', b'200'), consumed 1\n",
      "2025-01-02 18:03:05,883 - DEBUG - Decoded 33, consumed 1 bytes\n",
      "2025-01-02 18:03:05,883 - DEBUG - Decoded 22, consumed 1 bytes\n",
      "2025-01-02 18:03:05,884 - DEBUG - Decoded (b'date', b'Thu, 02 Jan 2025 17:03:05 GMT'), total consumed 24 bytes, indexed True\n",
      "2025-01-02 18:03:05,884 - DEBUG - Decoded 31, consumed 1 bytes\n",
      "2025-01-02 18:03:05,884 - DEBUG - Decoded 11, consumed 1 bytes\n",
      "2025-01-02 18:03:05,885 - DEBUG - Decoded (b'content-type', b'application/grpc'), total consumed 13 bytes, indexed True\n",
      "2025-01-02 18:03:05,885 - DEBUG - Decoded 14, consumed 1 bytes\n",
      "2025-01-02 18:03:05,885 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:03:05,885 - DEBUG - Decoded (b'grpc-accept-encoding', b'identity, deflate, gzip'), total consumed 34 bytes, indexed False\n",
      "2025-01-02 18:03:05,886 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:03:05,886 - DEBUG - Decoded 26, consumed 1 bytes\n",
      "2025-01-02 18:03:05,886 - DEBUG - Decoded (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), total consumed 46 bytes, indexed False\n",
      "2025-01-02 18:03:05,887 - DEBUG - Decoding b'\\x00\\x88\\x9a\\xca\\xc8\\xb2\\x124\\xda\\x8f\\x010\\x00\\x89\\x9a\\xca\\xc8\\xb5%B\\x071\\x7f\\x00'\n",
      "2025-01-02 18:03:05,887 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:03:05,887 - DEBUG - Decoded 1, consumed 1 bytes\n",
      "2025-01-02 18:03:05,887 - DEBUG - Decoded (b'grpc-status', <memory at 0x7c2f6d3f6800>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:03:05,888 - DEBUG - Decoded 9, consumed 1 bytes\n",
      "2025-01-02 18:03:05,888 - DEBUG - Decoded 0, consumed 1 bytes\n",
      "2025-01-02 18:03:05,888 - DEBUG - Decoded (b'grpc-message', <memory at 0x7c2f6d3f6b00>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:03:05,889 - DEBUG - Adding (b':method', b'POST') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,890 - DEBUG - Encoding 3 with 7 bits\n",
      "2025-01-02 18:03:05,890 - DEBUG - Adding (b':scheme', b'https') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,890 - DEBUG - Encoding 7 with 7 bits\n",
      "2025-01-02 18:03:05,890 - DEBUG - Adding (b':path', b'/modal.client.ModalClient/FunctionMap') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,890 - DEBUG - Encoding 4 with 6 bits\n",
      "2025-01-02 18:03:05,891 - DEBUG - Encoding 27 with 7 bits\n",
      "2025-01-02 18:03:05,891 - DEBUG - Adding (b':authority', b'api.modal.com:443') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,891 - DEBUG - Encoding 75 with 7 bits\n",
      "2025-01-02 18:03:05,891 - DEBUG - Adding (b'te', b'trailers') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,891 - DEBUG - Encoding 74 with 7 bits\n",
      "2025-01-02 18:03:05,892 - DEBUG - Adding (b'content-type', b'application/grpc') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,892 - DEBUG - Encoding 73 with 7 bits\n",
      "2025-01-02 18:03:05,892 - DEBUG - Adding (b'user-agent', b\"modal-client/0.70.1 (linux; cpython/3.10.15)'\") to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,892 - DEBUG - Encoding 72 with 7 bits\n",
      "2025-01-02 18:03:05,892 - DEBUG - Adding (b'x-idempotency-key', b'd694e1c0-4484-4ebb-88ce-46c268385455') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,893 - DEBUG - Encoding 71 with 6 bits\n",
      "2025-01-02 18:03:05,893 - DEBUG - Encoding 26 with 7 bits\n",
      "2025-01-02 18:03:05,893 - DEBUG - Adding (b'x-retry-attempt', b'0') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,893 - DEBUG - Encoding 71 with 7 bits\n",
      "2025-01-02 18:03:05,893 - DEBUG - Adding (b'x-modal-client-version', b'0.70.1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,894 - DEBUG - Encoding 70 with 7 bits\n",
      "2025-01-02 18:03:05,894 - DEBUG - Adding (b'x-modal-client-type', b'1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,894 - DEBUG - Encoding 69 with 7 bits\n",
      "2025-01-02 18:03:05,895 - DEBUG - Adding (b'x-modal-python-version', b'3.10.15') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,895 - DEBUG - Encoding 68 with 7 bits\n",
      "2025-01-02 18:03:05,896 - DEBUG - Adding (b'x-modal-node', b'mazerti-ASUS-TUF-Gaming-F15-FX506HM-TUF566HM') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,896 - DEBUG - Encoding 67 with 7 bits\n",
      "2025-01-02 18:03:05,896 - DEBUG - Adding (b'x-modal-platform', b'Linux-6.8.0_51_generic-x86_64') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,896 - DEBUG - Encoding 66 with 7 bits\n",
      "2025-01-02 18:03:05,896 - DEBUG - Adding (b'x-modal-token-id', b'ak-HLgx4CHd5JiKIluu51ZSos') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,897 - DEBUG - Encoding 65 with 7 bits\n",
      "2025-01-02 18:03:05,897 - DEBUG - Adding (b'x-modal-token-secret', b'as-lvSGANEGSqViUhZre9asLs') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:05,897 - DEBUG - Encoding 64 with 7 bits\n",
      "2025-01-02 18:03:05,898 - DEBUG - Encoded header block to b'\\x83\\x87D\\x9bb\\x93\\xc8:\\x17%\\x06-I_A\\xe4\\x1d\\x17\\xa81jK\\x18m\\xa8\\x891\\xea\\xd0:\\xff\\xcb\\xca\\xc9\\xc8\\x7f\\x08\\x9a\\x91\\xc7\\xda(H\\x05\\x9ai\\xe6\\x96h\\xb1\\xc6\\xb3\\xcf\\x10\\xab4\\xe1\\x04\\xe3\\xcc\\xbc\\xdbM\\xb7\\xc7\\xc6\\xc5\\xc4\\xc3\\xc2\\xc1\\xc0'\n",
      "2025-01-02 18:03:06,968 - DEBUG - Decoding b'\\x88a\\x96\\xdf=\\xbfJ\\x00Je\\x1dJ\\x08\\x02m@\\xbbp\\x0c\\xdc\\x03\\x8ab\\xd1\\xbf_\\x8b\\x1du\\xd0b\\r&=LMed\\x00\\x8e\\x9a\\xca\\xc8\\xb0\\xc8B\\xd6\\x95\\x8bQ\\x0f!\\xaa\\x9b\\x914\\x85\\xa9&O\\xaf\\xa5$,\\xb4\\r%\\xfaRof\\xaf\\x00\\x91Bl1\\x12\\xb2l\\x1dH\\xac\\xf6%d\\x14\\x96\\xd8d\\xfa\\x9a\\xa4~V\\x1c\\xc5\\x81\\x90\\xb6\\xcb\\x80\\x00>\\xd45D\\xa2\\xd9\\x0b\\xba\\xd8\\xef\\x9e\\x91\\x9a\\xa4\\x7f'\n",
      "2025-01-02 18:03:06,970 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:03:06,971 - DEBUG - Decoded (b':status', b'200'), consumed 1\n",
      "2025-01-02 18:03:06,972 - DEBUG - Decoded 33, consumed 1 bytes\n",
      "2025-01-02 18:03:06,972 - DEBUG - Decoded 22, consumed 1 bytes\n",
      "2025-01-02 18:03:06,974 - DEBUG - Decoded (b'date', b'Thu, 02 Jan 2025 17:03:06 GMT'), total consumed 24 bytes, indexed True\n",
      "2025-01-02 18:03:06,974 - DEBUG - Decoded 31, consumed 1 bytes\n",
      "2025-01-02 18:03:06,974 - DEBUG - Decoded 11, consumed 1 bytes\n",
      "2025-01-02 18:03:06,975 - DEBUG - Decoded (b'content-type', b'application/grpc'), total consumed 13 bytes, indexed True\n",
      "2025-01-02 18:03:06,975 - DEBUG - Decoded 14, consumed 1 bytes\n",
      "2025-01-02 18:03:06,975 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:03:06,975 - DEBUG - Decoded (b'grpc-accept-encoding', b'identity, deflate, gzip'), total consumed 34 bytes, indexed False\n",
      "2025-01-02 18:03:06,976 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:03:06,976 - DEBUG - Decoded 26, consumed 1 bytes\n",
      "2025-01-02 18:03:06,976 - DEBUG - Decoded (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), total consumed 46 bytes, indexed False\n",
      "2025-01-02 18:03:06,977 - DEBUG - Decoding b'\\x00\\x88\\x9a\\xca\\xc8\\xb2\\x124\\xda\\x8f\\x010\\x00\\x89\\x9a\\xca\\xc8\\xb5%B\\x071\\x7f\\x00'\n",
      "2025-01-02 18:03:06,977 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:03:06,977 - DEBUG - Decoded 1, consumed 1 bytes\n",
      "2025-01-02 18:03:06,977 - DEBUG - Decoded (b'grpc-status', <memory at 0x7c2f6d3f6b00>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:03:06,977 - DEBUG - Decoded 9, consumed 1 bytes\n",
      "2025-01-02 18:03:06,978 - DEBUG - Decoded 0, consumed 1 bytes\n",
      "2025-01-02 18:03:06,978 - DEBUG - Decoded (b'grpc-message', <memory at 0x7c2f6d3f68c0>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:03:06,979 - DEBUG - Adding (b':method', b'POST') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,979 - DEBUG - Encoding 3 with 7 bits\n",
      "2025-01-02 18:03:06,979 - DEBUG - Adding (b':scheme', b'https') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,979 - DEBUG - Encoding 7 with 7 bits\n",
      "2025-01-02 18:03:06,979 - DEBUG - Adding (b':path', b'/modal.client.ModalClient/FunctionGetOutputs') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,980 - DEBUG - Encoding 4 with 6 bits\n",
      "2025-01-02 18:03:06,980 - DEBUG - Encoding 32 with 7 bits\n",
      "2025-01-02 18:03:06,980 - DEBUG - Adding (b':authority', b'api.modal.com:443') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,980 - DEBUG - Encoding 77 with 7 bits\n",
      "2025-01-02 18:03:06,981 - DEBUG - Adding (b'grpc-timeout', b'59S') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,981 - DEBUG - Encoding 9 with 7 bits\n",
      "2025-01-02 18:03:06,981 - DEBUG - Encoding 3 with 7 bits\n",
      "2025-01-02 18:03:06,981 - DEBUG - Adding (b'te', b'trailers') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,981 - DEBUG - Encoding 77 with 7 bits\n",
      "2025-01-02 18:03:06,982 - DEBUG - Adding (b'content-type', b'application/grpc') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,982 - DEBUG - Encoding 76 with 7 bits\n",
      "2025-01-02 18:03:06,983 - DEBUG - Adding (b'user-agent', b\"modal-client/0.70.1 (linux; cpython/3.10.15)'\") to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,983 - DEBUG - Encoding 75 with 7 bits\n",
      "2025-01-02 18:03:06,983 - DEBUG - Adding (b'x-idempotency-key', b'9855e89b-3443-45b3-b556-1e4e8c24ad7a') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,983 - DEBUG - Encoding 64 with 6 bits\n",
      "2025-01-02 18:03:06,983 - DEBUG - Encoding 26 with 7 bits\n",
      "2025-01-02 18:03:06,983 - DEBUG - Adding (b'x-retry-attempt', b'0') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,984 - DEBUG - Encoding 74 with 7 bits\n",
      "2025-01-02 18:03:06,984 - DEBUG - Adding (b'x-modal-client-version', b'0.70.1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,984 - DEBUG - Encoding 73 with 7 bits\n",
      "2025-01-02 18:03:06,985 - DEBUG - Adding (b'x-modal-client-type', b'1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,985 - DEBUG - Encoding 72 with 7 bits\n",
      "2025-01-02 18:03:06,985 - DEBUG - Adding (b'x-modal-python-version', b'3.10.15') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,985 - DEBUG - Encoding 71 with 7 bits\n",
      "2025-01-02 18:03:06,986 - DEBUG - Adding (b'x-modal-node', b'mazerti-ASUS-TUF-Gaming-F15-FX506HM-TUF566HM') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,986 - DEBUG - Encoding 70 with 7 bits\n",
      "2025-01-02 18:03:06,986 - DEBUG - Adding (b'x-modal-platform', b'Linux-6.8.0_51_generic-x86_64') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,986 - DEBUG - Encoding 69 with 7 bits\n",
      "2025-01-02 18:03:06,987 - DEBUG - Adding (b'x-modal-token-id', b'ak-HLgx4CHd5JiKIluu51ZSos') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,987 - DEBUG - Encoding 68 with 7 bits\n",
      "2025-01-02 18:03:06,987 - DEBUG - Adding (b'x-modal-token-secret', b'as-lvSGANEGSqViUhZre9asLs') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:03:06,987 - DEBUG - Encoding 67 with 7 bits\n",
      "2025-01-02 18:03:06,988 - DEBUG - Encoded header block to b'\\x83\\x87D\\xa0b\\x93\\xc8:\\x17%\\x06-I_A\\xe4\\x1d\\x17\\xa81jK\\x18m\\xa8\\x891\\xea\\xc4T\\xea\\xb55\\xda\\x94\\x7f\\xcd@\\x89\\x9a\\xca\\xc8\\xb2MIOj\\x7f\\x83m\\xfd\\xdf\\xcd\\xcc\\xcb\\x7f\\x01\\x9a}\\xe6\\xdb+\\xcf\\xc6\\xb3-4\\xca\\xcd7\\x1b+F\\xdbn,\\x12\\xb4W\\x88&\\x87#\\xa3\\xca\\xc9\\xc8\\xc7\\xc6\\xc5\\xc4\\xc3'\n",
      "2025-01-02 18:04:02,228 - DEBUG - Decoding b'\\x88a\\x96\\xdf=\\xbfJ\\x00Je\\x1dJ\\x08\\x02m@\\xbbp\\r\\\\\\x00\\x94\\xc5\\xa3\\x7f_\\x8b\\x1du\\xd0b\\r&=LMed\\x00\\x8e\\x9a\\xca\\xc8\\xb0\\xc8B\\xd6\\x95\\x8bQ\\x0f!\\xaa\\x9b\\x914\\x85\\xa9&O\\xaf\\xa5$,\\xb4\\r%\\xfaRof\\xaf\\x00\\x91Bl1\\x12\\xb2l\\x1dH\\xac\\xf6%d\\x14\\x96\\xd8d\\xfa\\x9a\\xa4~V\\x1c\\xc5\\x81\\x90\\xb6\\xcb\\x80\\x00>\\xd45D\\xa2\\xd9\\x0b\\xba\\xd8\\xef\\x9e\\x91\\x9a\\xa4\\x7f'\n",
      "2025-01-02 18:04:02,228 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:04:02,229 - DEBUG - Decoded (b':status', b'200'), consumed 1\n",
      "2025-01-02 18:04:02,229 - DEBUG - Decoded 33, consumed 1 bytes\n",
      "2025-01-02 18:04:02,229 - DEBUG - Decoded 22, consumed 1 bytes\n",
      "2025-01-02 18:04:02,230 - DEBUG - Decoded (b'date', b'Thu, 02 Jan 2025 17:04:02 GMT'), total consumed 24 bytes, indexed True\n",
      "2025-01-02 18:04:02,230 - DEBUG - Decoded 31, consumed 1 bytes\n",
      "2025-01-02 18:04:02,230 - DEBUG - Decoded 11, consumed 1 bytes\n",
      "2025-01-02 18:04:02,231 - DEBUG - Decoded (b'content-type', b'application/grpc'), total consumed 13 bytes, indexed True\n",
      "2025-01-02 18:04:02,231 - DEBUG - Decoded 14, consumed 1 bytes\n",
      "2025-01-02 18:04:02,231 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:04:02,231 - DEBUG - Decoded (b'grpc-accept-encoding', b'identity, deflate, gzip'), total consumed 34 bytes, indexed False\n",
      "2025-01-02 18:04:02,232 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:04:02,232 - DEBUG - Decoded 26, consumed 1 bytes\n",
      "2025-01-02 18:04:02,232 - DEBUG - Decoded (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), total consumed 46 bytes, indexed False\n",
      "2025-01-02 18:04:02,233 - DEBUG - Decoding b'\\x00\\x88\\x9a\\xca\\xc8\\xb2\\x124\\xda\\x8f\\x010\\x00\\x89\\x9a\\xca\\xc8\\xb5%B\\x071\\x7f\\x00'\n",
      "2025-01-02 18:04:02,233 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:04:02,234 - DEBUG - Decoded 1, consumed 1 bytes\n",
      "2025-01-02 18:04:02,234 - DEBUG - Decoded (b'grpc-status', <memory at 0x7c2f6d3f6980>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:04:02,234 - DEBUG - Decoded 9, consumed 1 bytes\n",
      "2025-01-02 18:04:02,234 - DEBUG - Decoded 0, consumed 1 bytes\n",
      "2025-01-02 18:04:02,234 - DEBUG - Decoded (b'grpc-message', <memory at 0x7c2f6d3f6c80>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:04:02,235 - DEBUG - Adding (b':method', b'POST') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,235 - DEBUG - Encoding 3 with 7 bits\n",
      "2025-01-02 18:04:02,235 - DEBUG - Adding (b':scheme', b'https') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,236 - DEBUG - Encoding 7 with 7 bits\n",
      "2025-01-02 18:04:02,236 - DEBUG - Adding (b':path', b'/modal.client.ModalClient/FunctionGetOutputs') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,236 - DEBUG - Encoding 64 with 7 bits\n",
      "2025-01-02 18:04:02,236 - DEBUG - Adding (b':authority', b'api.modal.com:443') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,236 - DEBUG - Encoding 79 with 7 bits\n",
      "2025-01-02 18:04:02,237 - DEBUG - Adding (b'grpc-timeout', b'59S') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,237 - DEBUG - Encoding 63 with 7 bits\n",
      "2025-01-02 18:04:02,237 - DEBUG - Adding (b'te', b'trailers') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,237 - DEBUG - Encoding 78 with 7 bits\n",
      "2025-01-02 18:04:02,237 - DEBUG - Adding (b'content-type', b'application/grpc') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,238 - DEBUG - Encoding 77 with 7 bits\n",
      "2025-01-02 18:04:02,238 - DEBUG - Adding (b'user-agent', b\"modal-client/0.70.1 (linux; cpython/3.10.15)'\") to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,238 - DEBUG - Encoding 76 with 7 bits\n",
      "2025-01-02 18:04:02,238 - DEBUG - Adding (b'x-idempotency-key', b'45c94804-b50f-4398-b6f7-ebe07f742a8c') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,239 - DEBUG - Encoding 62 with 6 bits\n",
      "2025-01-02 18:04:02,240 - DEBUG - Encoding 26 with 7 bits\n",
      "2025-01-02 18:04:02,240 - DEBUG - Adding (b'x-retry-attempt', b'0') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,240 - DEBUG - Encoding 75 with 7 bits\n",
      "2025-01-02 18:04:02,241 - DEBUG - Adding (b'x-modal-client-version', b'0.70.1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,241 - DEBUG - Encoding 74 with 7 bits\n",
      "2025-01-02 18:04:02,241 - DEBUG - Adding (b'x-modal-client-type', b'1') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,241 - DEBUG - Encoding 73 with 7 bits\n",
      "2025-01-02 18:04:02,242 - DEBUG - Adding (b'x-modal-python-version', b'3.10.15') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,242 - DEBUG - Encoding 72 with 7 bits\n",
      "2025-01-02 18:04:02,242 - DEBUG - Adding (b'x-modal-node', b'mazerti-ASUS-TUF-Gaming-F15-FX506HM-TUF566HM') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,243 - DEBUG - Encoding 71 with 7 bits\n",
      "2025-01-02 18:04:02,243 - DEBUG - Adding (b'x-modal-platform', b'Linux-6.8.0_51_generic-x86_64') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,243 - DEBUG - Encoding 70 with 7 bits\n",
      "2025-01-02 18:04:02,243 - DEBUG - Adding (b'x-modal-token-id', b'ak-HLgx4CHd5JiKIluu51ZSos') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,244 - DEBUG - Encoding 69 with 7 bits\n",
      "2025-01-02 18:04:02,244 - DEBUG - Adding (b'x-modal-token-secret', b'as-lvSGANEGSqViUhZre9asLs') to the header table, sensitive:False, huffman:True\n",
      "2025-01-02 18:04:02,244 - DEBUG - Encoding 68 with 7 bits\n",
      "2025-01-02 18:04:02,244 - DEBUG - Encoded header block to b'\\x83\\x87\\xc0\\xcf\\xbf\\xce\\xcd\\xcc~\\x9ai\\xb2>\\xd3\\xc0ih\\xdb\\x04\\xab4\\xcb\\xef-\\x1b\\x92\\xba\\xb1c(\\x1d\\x95\\xd6\\x847\\x89\\xcb\\xca\\xc9\\xc8\\xc7\\xc6\\xc5\\xc4'\n",
      "2025-01-02 18:04:06,378 - DEBUG - Decoding b'\\x88a\\x96\\xdf=\\xbfJ\\x00Je\\x1dJ\\x08\\x02m@\\xbbp\\r\\\\\\x03\\x8ab\\xd1\\xbf_\\x8b\\x1du\\xd0b\\r&=LMed\\x00\\x8e\\x9a\\xca\\xc8\\xb0\\xc8B\\xd6\\x95\\x8bQ\\x0f!\\xaa\\x9b\\x914\\x85\\xa9&O\\xaf\\xa5$,\\xb4\\r%\\xfaRof\\xaf\\x00\\x91Bl1\\x12\\xb2l\\x1dH\\xac\\xf6%d\\x14\\x96\\xd8d\\xfa\\x9a\\xa4~V\\x1c\\xc5\\x81\\x90\\xb6\\xcb\\x80\\x00>\\xd45D\\xa2\\xd9\\x0b\\xba\\xd8\\xef\\x9e\\x91\\x9a\\xa4\\x7f'\n",
      "2025-01-02 18:04:06,379 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:04:06,379 - DEBUG - Decoded (b':status', b'200'), consumed 1\n",
      "2025-01-02 18:04:06,379 - DEBUG - Decoded 33, consumed 1 bytes\n",
      "2025-01-02 18:04:06,380 - DEBUG - Decoded 22, consumed 1 bytes\n",
      "2025-01-02 18:04:06,380 - DEBUG - Decoded (b'date', b'Thu, 02 Jan 2025 17:04:06 GMT'), total consumed 24 bytes, indexed True\n",
      "2025-01-02 18:04:06,380 - DEBUG - Decoded 31, consumed 1 bytes\n",
      "2025-01-02 18:04:06,380 - DEBUG - Decoded 11, consumed 1 bytes\n",
      "2025-01-02 18:04:06,380 - DEBUG - Decoded (b'content-type', b'application/grpc'), total consumed 13 bytes, indexed True\n",
      "2025-01-02 18:04:06,381 - DEBUG - Decoded 14, consumed 1 bytes\n",
      "2025-01-02 18:04:06,381 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:04:06,381 - DEBUG - Decoded (b'grpc-accept-encoding', b'identity, deflate, gzip'), total consumed 34 bytes, indexed False\n",
      "2025-01-02 18:04:06,381 - DEBUG - Decoded 17, consumed 1 bytes\n",
      "2025-01-02 18:04:06,382 - DEBUG - Decoded 26, consumed 1 bytes\n",
      "2025-01-02 18:04:06,382 - DEBUG - Decoded (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), total consumed 46 bytes, indexed False\n",
      "2025-01-02 18:04:06,382 - DEBUG - Decoding b'\\x00\\x88\\x9a\\xca\\xc8\\xb2\\x124\\xda\\x8f\\x010\\x00\\x89\\x9a\\xca\\xc8\\xb5%B\\x071\\x7f\\x00'\n",
      "2025-01-02 18:04:06,383 - DEBUG - Decoded 8, consumed 1 bytes\n",
      "2025-01-02 18:04:06,383 - DEBUG - Decoded 1, consumed 1 bytes\n",
      "2025-01-02 18:04:06,383 - DEBUG - Decoded (b'grpc-status', <memory at 0x7c2f6d3f6980>), total consumed 12 bytes, indexed False\n",
      "2025-01-02 18:04:06,384 - DEBUG - Decoded 9, consumed 1 bytes\n",
      "2025-01-02 18:04:06,384 - DEBUG - Decoded 0, consumed 1 bytes\n",
      "2025-01-02 18:04:06,384 - DEBUG - Decoded (b'grpc-message', <memory at 0x7c2f6d3f6f80>), total consumed 12 bytes, indexed False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(89, 274), match='Overall Comment:**\\nThe overall comment provided >\n",
      "<re.Match object; span=(350, 386), match='| Agrees             | 0%          |'>\n",
      "<re.Match object; span=(387, 423), match='| Disagrees          | 0%          |'>\n",
      "<re.Match object; span=(424, 460), match='| Unrelated          | 0%          |'>\n",
      "<re.Match object; span=(461, 496), match='| An error occurred  | 0%          '>\n",
      "<re.Match object; span=(86, 819), match=\"Overall Comment:\\nThe article discusses the diffi>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(87, 407), match=\"Overall Comment: The article cannot be evaluated >\n",
      "<re.Match object; span=(483, 518), match='| Agrees             | 0%         |'>\n",
      "<re.Match object; span=(519, 554), match='| Disagrees          | 0%         |'>\n",
      "<re.Match object; span=(555, 590), match='| Unrelated          | 0%         |'>\n",
      "<re.Match object; span=(591, 625), match='| An error occurred  | 50%        '>\n",
      "<re.Match object; span=(89, 390), match='Overall Comment:** \\nThe overall claim about Mach>\n",
      "<re.Match object; span=(466, 500), match='| Agrees             | 90        |'>\n",
      "<re.Match object; span=(501, 535), match='| Disagrees          | 0         |'>\n",
      "<re.Match object; span=(536, 570), match='| Unrelated          | 10        |'>\n",
      "<re.Match object; span=(571, 604), match='| An error occurred  | 0         '>\n",
      "<re.Match object; span=(89, 426), match='Overall Comment:** \\nThis article primarily discu>\n",
      "<re.Match object; span=(502, 536), match='| Agrees             | 80%       |'>\n",
      "<re.Match object; span=(537, 571), match='| Disagrees          | 20%       |'>\n",
      "<re.Match object; span=(572, 607), match='| Unrelated          | 0%         |'>\n",
      "<re.Match object; span=(608, 641), match='| An error occurred  | 0%        '>\n",
      "<re.Match object; span=(87, 307), match='Overall Comment:** \\nThe article discusses machin>\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(1308, 1342), match='| An error occurred  | 0%         '>\n",
      "[{'url': 'https://www.reddit.com/r/learnmachinelearning/comments/tsutuq/is_it_just_me_or_is_machine_learning_difficult_to/', 'publisher': 'Reddit', 'comment': 'The overall comment provided here should be empty since no significant information can be extracted from the provided instruction set regarding the claim and article.', 'stance': (None, 'error'), 'color': 'black'}, {'url': 'https://www.coursera.org/articles/is-machine-learning-hard', 'publisher': 'Coursera', 'comment': 'The overall claim about Machine Learning (ML) being easy was supported by the provided article, which stated that learning algorithms can be created through simple rules without much data. The article emphasized that ML does not need to be overly complex or difficult to implement.', 'stance': 'unrelated', 'color': 'white'}, {'url': 'https://www.nobledesktop.com/learn/machine-learning/how-difficult-is-it-to-learn-machine-learning', 'publisher': 'Nobledesktop', 'comment': 'This article primarily discusses the importance of machine learning and its applications across various industries. While the claim \"ML is easy\" is not directly supported by the article, the author provides insights on how to approach machine learning, the benefits of studying it, and comparisons with other fields.', 'stance': 'nuanced', 'color': '#c9dfe3'}]\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://8465bbdb4a0479bcac.gradio.live\n"
     ]
    }
   ],
   "source": [
    "import app\n",
    "\n",
    "app.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuesday-rush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
